{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import data_cleaning as cd\n",
    "import myfeatures as ft\n",
    "import mytrain as tr\n",
    "import mypredictions as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import data sources ###\n",
    "\n",
    "# Training data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "#Previously purchased subscriptions by account\n",
    "subscriptions = pd.read_csv('../data/subscriptions.csv')\n",
    "#display(subscriptions.head())\n",
    "\n",
    "# Location info for each patron and donation history\n",
    "accounts = pd.read_csv('../data/account.csv')\n",
    "#display(accounts.head())\n",
    "\n",
    "# Previous concerts by season\n",
    "concerts = pd.read_csv('../data/concerts.csv')\n",
    "#display(concerts.head())\n",
    "\n",
    "# List of planned concert sets for the 2014-15 season\n",
    "planned_concerts = pd.read_csv('../data/concerts_2014-15.csv')\n",
    "#display(planned_concerts.head())\n",
    "\n",
    "# Previously purchased tickets by account\n",
    "tickets = pd.read_csv('../data/tickets_all.csv')\n",
    "#display(tickets.head())\n",
    "\n",
    "# Location and demographic information for zipcodes\n",
    "zipcodes = pd.read_csv('../data/zipcodes.csv')\n",
    "#display(zipcodes.head())\n",
    "\n",
    "# Final test data\n",
    "final_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Subscriptions account ids: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    4736\n",
       "True     2205\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounts account ids: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True    6941\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickets account ids: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    6225\n",
       "True      716\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:\n",
      "Subscriptions account ids: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    2032\n",
       "True      943\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounts account ids: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True    2975\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickets account ids: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    2686\n",
       "True      289\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "# check how many account_id from training data are present in the other data sources\n",
    "print(\"Subscriptions account ids: \")\n",
    "display(pd.Series(train['account.id'].unique()).isin(subscriptions['account.id']).value_counts())\n",
    "\n",
    "print(\"Accounts account ids: \")\n",
    "display(pd.Series(train['account.id'].unique()).isin(accounts['account.id']).value_counts())\n",
    "\n",
    "print(\"Tickets account ids: \")\n",
    "\n",
    "tickets = tickets.loc[~tickets['price.level'].isin(['Adult', 'Youth', 'GA'])]\n",
    "display(pd.Series(train['account.id'].unique()).isin(tickets['account.id']).value_counts())\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "# check how many account_id from test data are present in the other data sources\n",
    "print(\"Subscriptions account ids: \")\n",
    "display(pd.Series(final_test['ID'].unique()).isin(subscriptions['account.id']).value_counts())\n",
    "\n",
    "print(\"Accounts account ids: \")\n",
    "display(pd.Series(final_test['ID'].unique()).isin(accounts['account.id']).value_counts())\n",
    "\n",
    "print(\"Tickets account ids: \")\n",
    "display(pd.Series(final_test['ID'].unique()).isin(tickets['account.id']).value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing subscriptions data:  account.id              0\n",
      "season                  0\n",
      "package                 6\n",
      "no.seats                0\n",
      "location                6\n",
      "section              4543\n",
      "price.level          3534\n",
      "subscription_tier       0\n",
      "multiple.subs           0\n",
      "dtype: int64 out of 28627 \n",
      "\n",
      "Dropping rows with missing data...\n",
      "Initial length of subscriptions:  28627\n",
      "Length of subscriptions after cleaning:  24083\n",
      "Missing accounts data:  account.id                     0\n",
      "shipping.zip.code          19569\n",
      "billing.zip.code            2955\n",
      "shipping.city              19561\n",
      "billing.city                2218\n",
      "relationship               19172\n",
      "amount.donated.2013            0\n",
      "amount.donated.lifetime        0\n",
      "no.donations.lifetime          0\n",
      "first.donated              14298\n",
      "dtype: int64 out of 19833 \n",
      "\n",
      "Dropping rows with missing data...\n",
      "Initial length of accounts:  19833\n",
      "Length of accounts after cleaning:  1\n",
      "Missing concerts data:  season          0\n",
      "concert.name    0\n",
      "set             0\n",
      "who             0\n",
      "what            0\n",
      "location        3\n",
      "dtype: int64 out of 103 \n",
      "\n",
      "Dropping rows with missing data...\n",
      "Initial length of concerts:  103\n",
      "Length of concerts after cleaning:  100\n",
      "Missing planned concerts data:  season          0\n",
      "concert.name    0\n",
      "set             0\n",
      "who             0\n",
      "what            0\n",
      "dtype: int64 out of 6 \n",
      "\n",
      "Missing tickets data:  account.id             0\n",
      "price.level          208\n",
      "no.seats               0\n",
      "marketing.source    2190\n",
      "season                 0\n",
      "location              44\n",
      "set                   22\n",
      "multiple.tickets       0\n",
      "dtype: int64 out of 2774 \n",
      "\n",
      "Keeping only relevant columns...\n",
      "Removing rows with non numeric values on price.level column\n",
      "Dropping rows with missing data...\n",
      "Initial length of tickets:  208\n",
      "Length of tickets after cleaning:  0\n",
      "Missing zipcodes data:  Zipcode                    0\n",
      "ZipCodeType                0\n",
      "City                       0\n",
      "State                      0\n",
      "LocationType               0\n",
      "Lat                      648\n",
      "Long                     648\n",
      "Location                   1\n",
      "Decommisioned              0\n",
      "TaxReturnsFiled        13643\n",
      "EstimatedPopulation    13643\n",
      "TotalWages             13678\n",
      "dtype: int64 out of 42522 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "subscriptions, accounts, concerts, planned_concerts, tickets, zipcodes = cd.clean_data(subscriptions, accounts, concerts, planned_concerts, tickets, zipcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    df_train = ft.build_features(train, accounts, subscriptions, tickets)\n",
    "\n",
    "    X_train = df_train.drop(columns=['account.id_x', 'account.id_y', 'label', 'ID'])\n",
    "    y_train = df_train['label']\n",
    "\n",
    "    #X_train.dropna(inplace=True)\n",
    "    print('X Train:')\n",
    "    display(X_train.head())\n",
    "    print('Training set size:', X_train.shape)\n",
    "\n",
    "    model = tr.train_randomforest(X_train, y_train)\n",
    "    preds = model.predict(X_train)\n",
    "\n",
    "    # Get training score\n",
    "    auroc_score = roc_auc_score(y_train, preds)\n",
    "\n",
    "    print(\"Training Auroc Score:\",auroc_score)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    # Predict on final test data\n",
    "    df_test = ft.build_features(final_test, accounts, subscriptions, tickets)\n",
    "    X_test = df_test.drop(columns=['account.id', 'ID'])\n",
    "\n",
    "    print('Testing set size:', X_test.shape)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    ids = final_test['ID']\n",
    "    pd.DataFrame({'ID': ids, 'Predicted': preds}).to_csv('../data/test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_subscriptions</th>\n",
       "      <th>avg_subscription_price_level</th>\n",
       "      <th>avg_subscription_tier</th>\n",
       "      <th>num_tickets</th>\n",
       "      <th>num_tickets_2013</th>\n",
       "      <th>avg_ticket_price_level</th>\n",
       "      <th>num_seats</th>\n",
       "      <th>num_seats_2013</th>\n",
       "      <th>amount.donated.2013</th>\n",
       "      <th>amount.donated.lifetime</th>\n",
       "      <th>no.donations.lifetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_subscriptions  avg_subscription_price_level  avg_subscription_tier  \\\n",
       "0                0.0                           0.0                    0.0   \n",
       "1                0.0                           0.0                    0.0   \n",
       "2                0.0                           0.0                    0.0   \n",
       "3                0.0                           0.0                    0.0   \n",
       "4                0.0                           0.0                    0.0   \n",
       "\n",
       "   num_tickets  num_tickets_2013  avg_ticket_price_level  num_seats  \\\n",
       "0          0.0               0.0                     0.0        0.0   \n",
       "1          0.0               0.0                     0.0        0.0   \n",
       "2          0.0               0.0                     0.0        0.0   \n",
       "3          0.0               0.0                     0.0        0.0   \n",
       "4          0.0               0.0                     0.0        0.0   \n",
       "\n",
       "   num_seats_2013  amount.donated.2013  amount.donated.lifetime  \\\n",
       "0             0.0                  NaN                      NaN   \n",
       "1             0.0                  NaN                      NaN   \n",
       "2             0.0                  NaN                      NaN   \n",
       "3             0.0                  NaN                      NaN   \n",
       "4             0.0                  NaN                      NaN   \n",
       "\n",
       "   no.donations.lifetime  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (6941, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training Random Forest...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jc/code/kaggle/philarmoniab-kaggle/notebooks/all_features.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jc/code/kaggle/philarmoniab-kaggle/notebooks/all_features.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_model \u001b[39m=\u001b[39m train_model()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jc/code/kaggle/philarmoniab-kaggle/notebooks/all_features.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_model(model\u001b[39m=\u001b[39mbest_model)\n",
      "\u001b[1;32m/Users/jc/code/kaggle/philarmoniab-kaggle/notebooks/all_features.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jc/code/kaggle/philarmoniab-kaggle/notebooks/all_features.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m display(X_train\u001b[39m.\u001b[39mhead())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jc/code/kaggle/philarmoniab-kaggle/notebooks/all_features.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining set size:\u001b[39m\u001b[39m'\u001b[39m, X_train\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jc/code/kaggle/philarmoniab-kaggle/notebooks/all_features.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m tr\u001b[39m.\u001b[39mtrain_randomforest(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jc/code/kaggle/philarmoniab-kaggle/notebooks/all_features.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jc/code/kaggle/philarmoniab-kaggle/notebooks/all_features.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Get training score\u001b[39;00m\n",
      "File \u001b[0;32m~/code/kaggle/philarmoniab-kaggle/notebooks/../scripts/mytrain.py:61\u001b[0m, in \u001b[0;36mtrain_randomforest\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     56\u001b[0m display(\u001b[39m\"\u001b[39m\u001b[39mTraining Random Forest...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier(criterion\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgini\u001b[39m\u001b[39m'\u001b[39m,max_depth\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, min_samples_leaf\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,n_estimators\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\n\u001b[1;32m     59\u001b[0m                              max_features\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,max_samples\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m model\u001b[39m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    349\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mDTYPE\n\u001b[1;32m    350\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[39m=\u001b[39morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[39m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[39m=\u001b[39mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[39m=\u001b[39mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[39m=\u001b[39mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "best_model = train_model()\n",
    "test_model(model=best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
